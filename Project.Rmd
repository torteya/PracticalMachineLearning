---
title: "Practical Machine Learning - Course Project"
author: "Carlos E. Martinez-Torteya"
date: "August 23, 2015"
output: html_document
pandoc_args: [
      "+RTS", "-Ksize",
      "-RTS"
    ]
---
#Introduction
In the present document we use the _Weight Lifting Exercises Database_ that took data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants ([more info on the dataset in this link](http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises)) to build a machine learning algorithm to predict how well the exercise was performed. We use a Random Forest algorithm with k-fold cross-validation. 

#Data Analysis
First we load the data and needed libraries. Note that in the original csv file there are many instances of "#DIV/0!" strings that will be read as NAs. We also remove the first seven columns as they consist of book-keeping variables that are not required for predictive purposes.

```{r, loadingData}
library(caret)
library(randomForest)
set.seed(1979)
data <- read.csv("pml-training.csv",na.strings=c("","NA","#DIV/0!"))
data <- data[,-(1:7)]
```

Now we will proceed to impose the threshold for keeping a feature being that it cannot contain more than 10% of NAs, and split the data into training and testing set with a proportion of 70/30.

```{r, NAs}
goodCols <- (colSums(is.na(data))/nrow(data)) < 0.1
goodData <- data[,goodCols]
inTrain <- createDataPartition(y=goodData$classe,p=0.7,list=FALSE)
training <- goodData[inTrain,]
testing <- goodData[-inTrain,]
dim(training)
```

Given that the training set is quite large, we will further reduce the dataset to build our prediction model --to save on computation time--, and check that the accuracy meets an acceptable level. We will take 30% of the full training set,

```{r, testing}
inSmallTrain <- createDataPartition(y=training$classe,p=0.3,list=FALSE)
smallTraining <- training[inSmallTrain,]
```

Now we proceed to train our model on this small (4123 observations) training subset. We train it with 5-fold cross-validation.

```{r, modelRF}
if (file.exists("modelRF.rds")) {
    # If model file already exists, read it
    modelRFSmall <- readRDS("modelRF.rds")
} else {
    # Otherwise, run random forest training and cache it
     modelRFSmall <- train(classe ~ ., method="rf", data=smallTraining, 
                           trControl=trainControl(method="cv",number=5,
                                                  returnData=FALSE, returnResamp="none", 
                                                  savePredictions=FALSE),
                           prox=TRUE,allowParallel=TRUE)
     saveRDS(modelRFSmall, file="modelRF.rds")}
```

We test this model on the entire _training_ set (13737 observations) as well as on the testing set (5885 observations) and check its accuracy.

```{r accuracy}
modelRFSmall$finalModel
confusionMatrix(predict(modelRFSmall,training),training$classe)
confusionMatrix(predict(modelRFSmall,testing),testing$classe)
```

Thus, it appears, this model is accurate enough: 0.98 on the full training set, and 0.97 on testing set; while the OOB estimate for the error rate is under 3%.